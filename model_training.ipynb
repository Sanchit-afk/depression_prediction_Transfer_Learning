{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting texthero\n",
      "  Downloading texthero-1.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from texthero) (3.1.3)\n",
      "Collecting gensim<4.0,>=3.6.0\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-win_amd64.whl (24.2 MB)\n",
      "Requirement already satisfied: tqdm>=4.3 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from texthero) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from texthero) (1.19.5)\n",
      "Collecting wordcloud>=1.5.0\n",
      "  Downloading wordcloud-1.8.1-cp37-cp37m-win_amd64.whl (154 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\sanchit\\appdata\\roaming\\python\\python37\\site-packages (from texthero) (0.22.2)\n",
      "Requirement already satisfied: pandas>=1.0.2 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from texthero) (1.3.3)\n",
      "Requirement already satisfied: nltk>=3.3 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from texthero) (3.4.5)\n",
      "Collecting unidecode>=1.1.1\n",
      "  Downloading Unidecode-1.3.3-py3-none-any.whl (235 kB)\n",
      "Requirement already satisfied: plotly>=4.2.0 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from texthero) (5.3.1)\n",
      "Collecting spacy<3.0.0\n",
      "  Downloading spacy-2.3.7-cp37-cp37m-win_amd64.whl (9.6 MB)\n",
      "Collecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp37-cp37m-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from gensim<4.0,>=3.6.0->texthero) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from gensim<4.0,>=3.6.0->texthero) (1.4.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.0->texthero) (2.8.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.0->texthero) (57.4.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from pandas>=1.0.2->texthero) (2019.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from plotly>=4.2.0->texthero) (8.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->texthero) (0.13.2)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp37-cp37m-win_amd64.whl (20 kB)\n",
      "Collecting thinc<7.5.0,>=7.4.1\n",
      "  Downloading thinc-7.4.5-cp37-cp37m-win_amd64.whl (888 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from spacy<3.0.0->texthero) (2.25.1)\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.5-cp37-cp37m-win_amd64.whl (176 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp37-cp37m-win_amd64.whl (35 kB)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp37-cp37m-win_amd64.whl (108 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp37-cp37m-win_amd64.whl (6.5 MB)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (4.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (2.2.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2019.11.28)\n",
      "Requirement already satisfied: colorama in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from tqdm>=4.3->texthero) (0.4.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\sanchit\\anaconda3\\lib\\site-packages (from wordcloud>=1.5.0->texthero) (7.0.0)\n",
      "Installing collected packages: murmurhash, cymem, wasabi, srsly, preshed, plac, catalogue, blis, thinc, smart-open, Cython, wordcloud, unidecode, spacy, gensim, texthero\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.15\n",
      "    Uninstalling Cython-0.29.15:\n",
      "      Successfully uninstalled Cython-0.29.15\n",
      "Successfully installed Cython-0.29.14 blis-0.7.5 catalogue-1.0.0 cymem-2.0.6 gensim-3.8.3 murmurhash-1.0.6 plac-1.1.3 preshed-3.0.6 smart-open-5.2.1 spacy-2.3.7 srsly-1.0.5 texthero-1.1.0 thinc-7.4.5 unidecode-1.3.3 wasabi-0.9.0 wordcloud-1.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparse-dot-topn 0.2.9 requires cython>=0.29.15, but you have cython 0.29.14 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\users\\sanchit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\sanchit\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install texthero -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marker</th>\n",
       "      <th>posts</th>\n",
       "      <th>clean_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Russia s Nuclear Threat Is More Than Words</td>\n",
       "      <td>russia nuclear threat words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depression</td>\n",
       "      <td>watching some of the 90s and older tv shows/ca...</td>\n",
       "      <td>watching 90s older tv shows cartoon makes feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depression</td>\n",
       "      <td>Cleaned the basement It was a pretty big deal ...</td>\n",
       "      <td>cleaned basement pretty big deal putting month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Drug Cartels to Mexican Police:  Join Us or Die</td>\n",
       "      <td>drug cartels mexican police join us die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Liquor market remains buoyant amid US recessio...</td>\n",
       "      <td>liquor market remains buoyant amid us recessio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166530</th>\n",
       "      <td>Normal</td>\n",
       "      <td>As buzz for \"Hustlers\" grows, the battle for t...</td>\n",
       "      <td>buzz hustlers grows battle top spot domestic b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166531</th>\n",
       "      <td>depression</td>\n",
       "      <td>Why can't I just die already... Tired of life,...</td>\n",
       "      <td>die already tired life way much explain wish d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166532</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Pakistan lifts the ban on YouTube</td>\n",
       "      <td>pakistan lifts ban youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166533</th>\n",
       "      <td>depression</td>\n",
       "      <td>How to over come So I have suffered from bad A...</td>\n",
       "      <td>come suffered bad allergies chronic rhinitis '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166534</th>\n",
       "      <td>depression</td>\n",
       "      <td>I have a solid mental block against medication...</td>\n",
       "      <td>solid mental block medication depression thera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Marker                                              posts  \\\n",
       "0           Normal         Russia s Nuclear Threat Is More Than Words   \n",
       "1       depression  watching some of the 90s and older tv shows/ca...   \n",
       "2       depression  Cleaned the basement It was a pretty big deal ...   \n",
       "3           Normal   Drug Cartels to Mexican Police:  Join Us or Die    \n",
       "4           Normal  Liquor market remains buoyant amid US recessio...   \n",
       "...            ...                                                ...   \n",
       "166530      Normal  As buzz for \"Hustlers\" grows, the battle for t...   \n",
       "166531  depression  Why can't I just die already... Tired of life,...   \n",
       "166532      Normal                  Pakistan lifts the ban on YouTube   \n",
       "166533  depression  How to over come So I have suffered from bad A...   \n",
       "166534  depression  I have a solid mental block against medication...   \n",
       "\n",
       "                                               clean_data  \n",
       "0                             russia nuclear threat words  \n",
       "1       watching 90s older tv shows cartoon makes feel...  \n",
       "2       cleaned basement pretty big deal putting month...  \n",
       "3                 drug cartels mexican police join us die  \n",
       "4       liquor market remains buoyant amid us recessio...  \n",
       "...                                                   ...  \n",
       "166530  buzz hustlers grows battle top spot domestic b...  \n",
       "166531  die already tired life way much explain wish d...  \n",
       "166532                         pakistan lifts ban youtube  \n",
       "166533  come suffered bad allergies chronic rhinitis '...  \n",
       "166534  solid mental block medication depression thera...  \n",
       "\n",
       "[166535 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text_data = pd.read_csv('D:/Sem 8/END SEM PROJECT/clean_data.csv')\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import texthero as hero\n",
    "text_data['clean_data'] = hero.clean(text_data['posts'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               russia nuclear threat words\n",
       "1         watching 90s older tv shows cartoon makes feel...\n",
       "2         cleaned basement pretty big deal putting month...\n",
       "3                   drug cartels mexican police join us die\n",
       "4         liquor market remains buoyant amid us recessio...\n",
       "                                ...                        \n",
       "166530    buzz hustlers grows battle top spot domestic b...\n",
       "166531    die already tired life way much explain wish d...\n",
       "166532                           pakistan lifts ban youtube\n",
       "166533    come suffered bad allergies chronic rhinitis '...\n",
       "166534    solid mental block medication depression thera...\n",
       "Name: clean_data, Length: 166535, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data['clean_data'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = text_data['clean_data'].tolist()\n",
    "type(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('D:/Sem 8/END SEM PROJECT/clean_data.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "text_data.to_csv(filepath,index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "# sentences = ['This framework generates embeddings for each input sentence',\n",
    "#     'Sentences are passed as a list of string.',\n",
    "#     'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "sentences = text_data['clean_data'].tolist() \n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Print the embeddings\n",
    "# for sentence, embedding in zip(sentences, embeddings):\n",
    "#     print(\"Sentence:\", sentence)\n",
    "#     print(\"Embedding:\", embedding)\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166535, 384)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez('embeddings.npz', embeddings)\n",
    "# embeddings = np.load('embeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Sem 6\\\\data'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of variance ratios:  0.8343722804162809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_model = PCA(n_components=100)\n",
    "pca_model.fit(embedds)\n",
    "print(\"Sum of variance ratios: \",sum(pca_model.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': 0, 'depression': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asarray(text_data['Marker'])\n",
    "label_map = {cat:index for index,cat in enumerate(np.unique(y))}\n",
    "y_prep = np.asarray([label_map[l] for l in y])\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166535, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_comps = pca_model.transform(embedds)\n",
    "x_comps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marker</th>\n",
       "      <th>clean_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>russia nuclear threat words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depression</td>\n",
       "      <td>watching 90s older tv shows cartoon makes feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depression</td>\n",
       "      <td>cleaned basement pretty big deal putting month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>drug cartels mexican police join us die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal</td>\n",
       "      <td>liquor market remains buoyant amid us recessio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166530</th>\n",
       "      <td>Normal</td>\n",
       "      <td>buzz hustlers grows battle top spot domestic b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166531</th>\n",
       "      <td>depression</td>\n",
       "      <td>die already tired life way much explain wish d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166532</th>\n",
       "      <td>Normal</td>\n",
       "      <td>pakistan lifts ban youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166533</th>\n",
       "      <td>depression</td>\n",
       "      <td>come suffered bad allergies chronic rhinitis '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166534</th>\n",
       "      <td>depression</td>\n",
       "      <td>solid mental block medication depression thera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Marker                                         clean_data\n",
       "0           Normal                        russia nuclear threat words\n",
       "1       depression  watching 90s older tv shows cartoon makes feel...\n",
       "2       depression  cleaned basement pretty big deal putting month...\n",
       "3           Normal            drug cartels mexican police join us die\n",
       "4           Normal  liquor market remains buoyant amid us recessio...\n",
       "...            ...                                                ...\n",
       "166530      Normal  buzz hustlers grows battle top spot domestic b...\n",
       "166531  depression  die already tired life way much explain wish d...\n",
       "166532      Normal                         pakistan lifts ban youtube\n",
       "166533  depression  come suffered bad allergies chronic rhinitis '...\n",
       "166534  depression  solid mental block medication depression thera...\n",
       "\n",
       "[166535 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_text = pd.read_csv('D:/Sem 8/END SEM PROJECT/clean_data_text.csv')\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings = np.load('embeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arr_0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedds=embeddings['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "single = x_comps[166533]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.651129  , -0.11504638, -0.46947262,  0.07619137, -0.52501535,\n",
       "        -0.07911602,  0.12837148, -0.20439208,  0.05443027,  0.551519  ,\n",
       "        -0.19587204,  0.16509515,  0.31057703, -1.0120077 , -0.22210765,\n",
       "         0.46117073,  0.4543437 ,  0.22288089,  0.04500074,  0.1374414 ,\n",
       "        -0.2940935 , -0.35381106,  0.30556428, -0.29716063, -0.19989936,\n",
       "         0.14398968, -0.70666885, -1.0983615 ,  0.09617344,  0.22082715,\n",
       "         0.01268007, -0.21702012, -0.33349103, -0.5736356 ,  0.55041766,\n",
       "        -0.33100224,  0.48129013,  0.38032004, -0.03948212,  0.3834722 ,\n",
       "         0.4246366 , -0.22832407,  0.37083006,  0.06688575,  0.74142116,\n",
       "         0.02980442, -0.20399298,  0.0649858 , -0.2986439 ,  0.12807715,\n",
       "        -0.01186774, -0.39184105, -0.19594091, -0.44369552, -0.3859027 ,\n",
       "         0.3785161 ,  0.00979452, -0.05600143,  0.11149953,  0.48802388,\n",
       "         0.43237406,  0.29916987,  0.02545708, -0.34982434,  0.5679552 ,\n",
       "         0.2556388 ,  0.36476433, -0.30816513,  0.27782202, -0.41278988,\n",
       "        -0.14420673,  0.19992277,  0.50741076, -0.01632247, -0.2638316 ,\n",
       "         0.00467916,  0.10955775,  0.30387253,  0.16021785, -0.05312721,\n",
       "         0.45287943, -0.14371538, -0.07316945,  0.25091732,  0.31607363,\n",
       "         0.10401304,  0.31200832, -0.09841306,  0.13099323,  0.12812018,\n",
       "        -0.38983244, -0.21243018,  0.13304421, -0.3263903 ,  0.30170885,\n",
       "        -0.27981848,  0.12924352, -0.27789706, -0.07936487,  0.13705318]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133228, 100)\n",
      "(33307, 100)\n",
      "(133228,)\n",
      "(33307,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_comps,y_prep,test_size=0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier has fitted, this process took 207.08 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() \n",
    "\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(x_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "process = round(end-start,2)\n",
    "print(\"Support Vector Machine Classifier has fitted, this process took {} seconds\".format(process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9932446632839943"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings = np.load('newembeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedds=embeddings['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192244, 384)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marker</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>depression</td>\n",
       "      <td>My birthday is tomorrow. Yes, I will be turnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depression</td>\n",
       "      <td>Iâm so fucking lonely. I  know most of this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depression</td>\n",
       "      <td>I feel like Iâm losing my friends Hi.....Iâ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>this is smack ONE OF THE BEST TRANCE SONGS IN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depression</td>\n",
       "      <td>My boyfriend is controlling me even though he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192239</th>\n",
       "      <td>depression</td>\n",
       "      <td>Is there a problem that is objectively too sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192240</th>\n",
       "      <td>Normal</td>\n",
       "      <td>nah, a nice big bagel! Too early for burgers!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192241</th>\n",
       "      <td>Normal</td>\n",
       "      <td>oh oh found some clothes!! And i love em xD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192242</th>\n",
       "      <td>Normal</td>\n",
       "      <td>it's an awesome movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192243</th>\n",
       "      <td>depression</td>\n",
       "      <td>I just want to end it all I fucking hate my li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192244 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Marker                                              Posts\n",
       "0       depression  My birthday is tomorrow. Yes, I will be turnin...\n",
       "1       depression  Iâm so fucking lonely. I  know most of this ...\n",
       "2       depression  I feel like Iâm losing my friends Hi.....Iâ...\n",
       "3           Normal  this is smack ONE OF THE BEST TRANCE SONGS IN ...\n",
       "4       depression  My boyfriend is controlling me even though he ...\n",
       "...            ...                                                ...\n",
       "192239  depression  Is there a problem that is objectively too sma...\n",
       "192240      Normal      nah, a nice big bagel! Too early for burgers!\n",
       "192241      Normal        oh oh found some clothes!! And i love em xD\n",
       "192242      Normal                              it's an awesome movie\n",
       "192243  depression  I just want to end it all I fucking hate my li...\n",
       "\n",
       "[192244 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text_data = pd.read_csv('D:/Sem 8/END SEM PROJECT/mixed_data.csv',encoding = \"ISO-8859-1\")\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': 0, 'depression': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asarray(text_data['Marker'])\n",
    "label_map = {cat:index for index,cat in enumerate(np.unique(y))}\n",
    "y_prep = np.asarray([label_map[l] for l in y])\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153795, 384)\n",
      "(38449, 384)\n",
      "(153795,)\n",
      "(38449,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "x_train,x_test,y_train,y_test = train_test_split(embedds,y_prep,test_size=0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier has fitted, this process took 2782.03 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() \n",
    "\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(x_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "process = round(end-start,2)\n",
    "print(\"Support Vector Machine Classifier has fitted, this process took {} seconds\".format(process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "single = embedds[2].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876979895445915"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>clean_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family is very supportive but despite that ...</td>\n",
       "      <td>family supportive despite lack motivation make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have always been encouraged to pursue what i...</td>\n",
       "      <td>always encouraged pursue like always made feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont stress about it a lot</td>\n",
       "      <td>dont stress lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling low and listening to sad songs m...</td>\n",
       "      <td>feeling low listening sad songs made depressed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am very happy about it</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample  \\\n",
       "0  My family is very supportive but despite that ...   \n",
       "1  I have always been encouraged to pursue what i...   \n",
       "2                       i dont stress about it a lot   \n",
       "3  i was feeling low and listening to sad songs m...   \n",
       "4                           i am very happy about it   \n",
       "\n",
       "                                          clean_data  \n",
       "0  family supportive despite lack motivation make...  \n",
       "1  always encouraged pursue like always made feel...  \n",
       "2                                    dont stress lot  \n",
       "3  feeling low listening sad songs made depressed...  \n",
       "4                                              happy  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import texthero as hero\n",
    "sample = {'','I have always been encouraged to pursue what i like and its always made me feel content and happy','My family is very supportive but despite that i lack motivation and that makes me feel low. Sometimes i feel like i should end it all','i dont stress about it a lot','i was feeling low and listening to sad songs made me more depressed i started thinking that i am worth nothing','i am very happy about it'}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(sample, columns = ['sample'])\n",
    "df['clean_data'] = hero.clean(df['sample'])\n",
    "sample_sent = df['clean_data'].tolist() \n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "samp_embeddings = model.encode(sample_sent)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.predict(samp_embeddings[2].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single = embedds[3].reshape(1,-1)\n",
    "svm_classifier.predict(single.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'depression_model.sav'\n",
    "pickle.dump(svm_classifier, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
